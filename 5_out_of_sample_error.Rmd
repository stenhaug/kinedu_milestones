---
title: "5_out_of_sample_error"
output: html_document
---

- can look at which students (broken down by age probably) have the most error

- do a comparison between good and bad models

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mirt)
library(rsample)
theme_set(theme_classic(base_size = 14))
options(pillar.sigfig = 6)
R.utils::sourceDirectory("~/Google_Drive/5_Projects/irt_comparison3/R")
```

# Prepare data

```{r}
# read in
fix_names <- function(x) ifelse(x == "", paste0("X__", 1:length(x) - 1), x)

d_raw <- 
  readxl::read_xlsx(
    "data/norming2/Kinedu Norming Survey Raw Data - May 15 2018.xlsx", 
    .name_repair = fix_names
  )

# prepare irt matrix
d <- 
  d_raw %>%
  mutate(age = as.numeric(X__422), 
         gestation = as.numeric(X__3),
         kinder = as.numeric(X__4),
         diagnosis = as.numeric(X__1), 
         id = `Nombre variable`) %>%
  slice(4:n()) %>% # drop two top label rows. 
  select(-starts_with("X"), -`Nombre variable`) %>%
  gather(code, response, abs_183:color_679) %>%
  mutate(code = str_replace(code, "^d_","d"),
         code = str_replace_all(code, " ", ""),
         code = str_replace(code, "^e_",""),
         code2 = code) %>%
  separate(code2, into = c("category","number")) %>%
  select(-number) %>%
  mutate(response = as.numeric(response)) %>% 
  filter(age != 0) # DROP AGE 0

d_wide <- d %>%
  select(id, code, response) %>%
  spread(code, response)
  
d_mat <- d_wide %>%
  select(-id) %>% 
  data.frame %>%
  data.matrix

colnames(d_mat) <- sort(unique(d$code))
rownames(d_mat) <- d_wide$id

# lots of items / students is relatively high
dim(d_mat)

# we want area for each item
areas <- 
  readxl::read_excel("data/norming2/0-48 milestones y abreviaciones (viejos vs nuevos).xlsx") %>% 
  select(
    abbrev = Abbreviation,
    milestone = `Milestone ID...9`,
    area = Area
  ) %>% 
  mutate(abbrev = str_replace(abbrev, "^e_", "")) %>% 
  mutate(abbrev = str_replace(abbrev, "_", "")) %>% 
  mutate(paste = paste0(abbrev, "_", milestone))

all(colnames(d_mat) %in% areas$paste)

item_area <- 
  areas$area[match(colnames(d_mat), areas$paste)]

d_mat %>% write_rds("data-clean/d_mat.rds")
areas %>% write_rds("data-clean/areas.rds")
```

# Exploratory models

## example

```{r}
the_data <- d_mat[1:300, 1:20]

splits_df <- vfold_cv(the_data, v = 2) # crank

list_of_args <- 
  list(
    model = 2,
    itemtype = "2PL", 
    quadpts = 20, # crank 
    TOL = 0.0002, # crank
    technical = list(theta_lim = c(-6, 6), NCYCLES = 100), # crank
    verbose = TRUE
  )

splits_with_log_lik <-
  splits_df %>% 
  mutate(
    model = 
      splits %>% 
      map(~ c(list(data = training(.)), list_of_args)) %>% 
      map(~ do.call(mirt, .)),
    log_lik_test = 
      map2_dbl(
        splits, 
        model, 
        ~ calc_log_lik_ghq2(.y, testing(.x))
      )
  )

(per_person <- exp(sum(splits_with_log_lik$log_lik_test) / nrow(the_data)))
(per_person_item <- per_person^(1 / ncol(the_data))) 
# alternative: exp(sum(splits_with_log_lik$log_lik_test) / prod(dim(the_data)))
```

## define

```{r}
factors_itemtype_splits_df_to_splits_with_log_lik <- function(factors, itemtype, splits_df){
  # splits_df_factors_itemtype_to_splits_with_log_lik(2, "2PL", splits_df)
  splits_df %>% 
  mutate(
    model = 
      splits %>% 
      map(
        ~ list(
            data = training(.), 
            model = factors,
            itemtype = itemtype, 
            quadpts = 20, # crank 
            TOL = 0.0002, # crank
            technical = list(theta_lim = c(-6, 6), NCYCLES = 500), # crank
            verbose = TRUE
          )
      ) %>% 
      map(~ do.call(mirt, .)),
    log_lik_test = 
      map2_dbl(
        splits, 
        model, 
        ~ calc_log_lik_ghq2(.y, testing(.x))
      )
  )
}
```

## execute

```{r}
# replace the_data everywhere and crank it up!
splits_df <- vfold_cv(d_mat, v = 3)

out <- 
  tribble(
    ~factors,  ~itemtype,
        1,      "Rasch",
        1,      "2PL",
        1,      "3PL",
        2,      "2PL",
        2,      "3PL",
        3,      "2PL",
        3,      "3PL",
  ) %>% 
  mutate(
    splits_with_log_lik = 
      map2(
          factors, 
          itemtype, 
          factors_itemtype_splits_df_to_splits_with_log_lik, 
          splits_df
      )
  ) %>%
  mutate(
    ll_person = 
      splits_with_log_lik %>% 
      map_dbl(~ exp(sum(.$log_lik_test) / nrow(the_data))),
    ll_person_item = ll_person ^ (1 / ncol(d_mat))
  )

out %>% 
  mutate(
    ll_person = 
      splits_with_log_lik %>% 
      map_dbl(~ exp(sum(.$log_lik_test) / nrow(d_mat))),
    ll_person_item = ll_person ^ (1 / ncol(d_mat))
  )

sum(out$splits_with_log_lik[[1]]$log_lik_test)
```

# Confirmatory MIRT models

```{r}
# just physical
s <- 
  mirt.model(
    glue::glue(
    "Phys = {paste(which(item_area == 'Physical'), collapse = ',')}
    NonPhys = {paste(which(item_area != 'Physical'), collapse = ',')}
    COV = Phys*NonPhys"
    )
  )
  
model_phys <- 
  mirt(
    d_mat, 
    s, 
    itemtype = "2PL", 
    method = "EM",
    quadpts = 20, # crank 
    TOL = 0.0002, # crank
    technical = list(theta_lim = c(-6, 6), NCYCLES = 100), # crank
    verbose = TRUE
  )

model_phys2 <- 
  mirt(
    d_mat, 
    s, 
    itemtype = "2PL", 
    method = "QMCEM",
    quadpts = 20, # crank 
    TOL = 0.0002, # crank
    technical = list(theta_lim = c(-6, 6), NCYCLES = 100), # crank
    verbose = TRUE
  )

# everything
logLik(model_phys)

s <- 
  mirt.model(
    glue::glue(
    "cog = {paste(which(item_area == 'Cognitive'), collapse = ',')}
    sem = {paste(which(item_area == 'Social & Emotional'), collapse = ',')}
    ling = {paste(which(item_area == 'Linguistic'), collapse = ',')}
    phys = {paste(which(item_area == 'Physical'), collapse = ',')}"
    )
  )
  
model_all <- 
  mirt(
    d_mat, 
    s, 
    itemtype = "2PL", 
    method = "MCEM",
    # quadpts = 50, # crank 
    TOL = 0.0002, # crank
    technical = list(theta_lim = c(-6, 6), NCYCLES = 100), # crank
    verbose = TRUE
  )

anova(model_all, model_phys)

anova(model_phys2, model_phys)

unique(item_area)
```



