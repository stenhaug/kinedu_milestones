---
title: "The latent factor structure of child development"
bibliography: cogsci_ref.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{Anonymous Cogsci Submission}

abstract: >
    Piaget famously proposed a stage theory of child development. More recently, researchers have proposed more modern theories of child development. Despite the abundance of theory, there is little empirical work on the dimensionality of child development. We investigate the dimensionality of child development by comparing a variety of item response models fit to data from a Mexico-based child development app, Kinedu. We find evidence that child development from 0 - 55 months of age has three dimensions. We also find evidence that dimensionality increases across the age-span. These results suggest the value of more precise measures of child development, which we hope will both enrichen our understanding of developmental processes and provide the groundwork for improved interventions for developmental delay.
    
keywords: >
    child development; milestones; item response theory; model comparison
    
output: cogsci2016::cogsci_paper
header-includes:
- \usepackage{amsmath}
- \usepackage{bm}
- \usepackage{xcolor}
- \newcommand\myworries[1]{\textcolor{red}{#1}}
final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)

library(tidyverse)
theme_set(theme_classic())

# load in
areas <- read_rds(here::here("data-clean/areas.rds"))
d <- read_rds(here::here("data-clean/d.rds"))
d_mat <- read_rds(here::here("data-clean/d_mat.rds"))
item_area <- areas$area[match(colnames(d_mat), areas$paste)]

fix_names <- function(x) ifelse(x == "", paste0("X__", 1:length(x) - 1), x)

d_raw <- 
  readxl::read_xlsx(
    here::here("data/norming2/Kinedu Norming Survey Raw Data - May 15 2018.xlsx"),
    .name_repair = fix_names
  )

# remove ages < 1
ages <-
    d %>%
    group_by(id) %>%
    summarize(age = age[1]) %>%
    filter(age > 1)

d_mat <- d_mat[row.names(d_mat) %in% ages$id, ]

d <- d %>% filter(age > 1)

# get milestones
milestones <-
    d_raw %>%
    select(abs_183:color_679) %>%
    slice(3) %>%
    gather(code, name) %>%
    mutate(short_name = str_sub(name, start = 0, end = 40),
           code = str_replace(code, "^d_","d"),
           code = str_replace(code, "^e_","")) %>%
    mutate(code2 = code) %>%
    separate(code2, into = c("category","number")) %>%
    select(-number)

ms <- milestones %>% mutate(code = str_remove(code, " "))
```

# Introduction

How do young children grow and change? Is child development a single unified process or a host of different processes, each with their own constraints and timescale? Piaget famously proposed a stage theory in which many seemingly distinct mental processes developed in concert through the operation of the same principles across domains [@flavell1963developmental]. In contrast, modern theories propose that different facets of children's mental life develop on their own timetable [@gelman1983preschoolers]. And the grandmother of one author of this paper was known to assert that developmental milestones were in compensatory relationships with one another ("children either walk early or else they talk early"). 

This question is important not only from a theoretical perspective but also for application. The process of assessing children's developmental status critically depends on our assumptions about the nature of that status — in particular, whether there is a single unified process that can be measured via some score derived from subprocesses. In this sense, questions about the nature and structure of development are psychometric questions [@borsboom2005measuring]. Such psychometric analysis investigating the dimensionality of change has been studied extensively in the case of cognitive aging [e.g., @balinsky1941analysis; @li1999test] but has received less attention in early childhood.

Our goal is to describe the psychometric structure of development. We take as our starting point the idea that psychometric models can instantiate hypotheses about psychological structure in ways that can be assessed via their fit to data. We adopt the framework of item response theory (IRT). IRT models allow us to capture how responses to such questions track both with individual children's abilities as well as with the measurement properties of the questions (and underlying milestones). In particular, our interest is in comparing within a family of multidimensional IRT models in order to gain insight into the underlying dimensionality of early childhood development. 

In a standard factor-analytic approach (which multi-dimensional IRT extends), a solution with N factors partitions observed variance into factors, suggesting dimensions of variation in the sample. One substantial complication to this perspective for analyzing developmental data is the issue that the dimensionality of children's variation could itself change developmentally. Indeed, the dedifferentiation hypothesis of cognitive aging — that distinct factors collapse is such a hypothesis. To address this challenge, we use a new set of cross-validation methods to investigate changes in dimensionality. 

We use milestone data for our investigation. Global assessment of developmental status via a series of binary questions (e.g., "Can your child walk at least ten steps unassisted?") is both a standard feature of pediatrician visits [@sheldrick2019establishing] and a gold standard for child development in the research and intervention communities [@bayley2009bayley; @bricker1999ages; @mccoy2019preschool]. In such assessments, which are typically but not always conducted via parent report, developmental progress is pooled across domains like motor development or language. Thus, these instruments implicitly assume a unifactorial model, although some also provide subscale scores [@bayley2009bayley].

Unfortunately, these instruments are commercial products, and hence normative data at the item level are typically not available for analysis. In the current paper, we thus analyze a new set of data from a set of 414 milestone questions administered online to a group of 1946 middle-class Mexican parents of children from 0 to 55 months of age. This very comprehensive milestone set allows us to ask questions about how variation in developmental growth can be partitioned across age and face-valid domains (language, cognition, motor, and socio-emotional development).

We first describe our dataset. We then introduce the family of item response models that we use and the way in which we compare performance across these models. These models allow us to consider the overall dimensionality of our dataset, which we then follow up on by looking for evidence of change in dimensionality across development. We end by considering the limitations, implications, and next steps for this work.

# Data

A child’s development can be thought of as the set of developmental milestones that they have reached at a particular point in time. This conceptualization results in data with the same structure as the item response data common to educational measurement. In education, item response data is most typically students responding to test items (i.e., questions) and, in the dichotomous case, getting each question either correct or incorrect. In the context of child development, the child is the “student,” and each developmental milestone is the “item.”

We use Kinedu, a Mexico-based child development app, as a source for this type of data. When parents first start using the Kinedu app, they are asked a series of questions about which developmental milestones their child has reached. We consider the 1946 children between 2 and 55 months of age whose parents responded to all 414 of the developmental milestones. Each developmental miletone on Kinedu is mapped to a milestone group: physical, cognitive, linguistic, or social & emotional. Table \ref{tab:examples} shows the number of developmental milestones in each group along with an example milestone from each group translated to English.

```{r examples}
areas %>%
    filter(paste %in% colnames(d_mat)) %>%
    group_by(area) %>%
    mutate(count = n()) %>%
    slice(1) %>%
    ungroup() %>%
    left_join(ms, by = c("paste" = "code")) %>%
    select(Group = area, Count = count, spanish = short_name) %>%
    select(-spanish) %>% 
    arrange(desc(Count)) %>%
    mutate(`Example milestone` = c(
        "Stands on their toes",
        "Finds objects on the floor",
        "Babbles to imitate conversations",
        "Complains when play is interrupted"
    )) %>% 
    knitr::kable("latex", caption = "Developmental milestone groups and examples") %>% 
    kableExtra::kable_styling(font_size = 8, latex_options = "hold_position")
```

Figure \ref{fig:growth} shows the age (in months) and number of developmental milestones for each child. At 12 months old, most children have reached about 200 developmental milestones. At 24 months old, most children have reached about 300 developmental milestones. Finally, at 48 months old, most children have reached about 375 of the 414 developmental milestones.

```{r growth, fig.cap = 'Number of milestones by age and percentile curves. Dots represent individual children. ', warning = FALSE}
source(here::here("data-emailed-from-mike/predictQR_fixed.R"))
library(quantregGrowth)

by_age <- 
    d %>%
    group_by(id) %>%
    summarise(
        age = age[1], 
        response = sum(response)
    )

excl <- 
    by_age %>%
    filter(age <= 1) %>%
    pull(id)

by_age <- filter(by_age, !(id %in% excl))
d <- filter(d, !(id %in% excl))

taus <-  c(0.1, 0.25, 0.5, 0.75, 0.9)

mod <- gcrq(formula = response ~ ps(age, monotone = 1, lambda = 1000), 
     tau = taus, data = by_age)

the_ages <- 1:55
newdata <- data.frame(age = the_ages)

preds <- predictQR_fixed(mod, newdata = newdata) %>%
  data.frame %>%
  mutate(age = the_ages) %>%
  gather(Percentile, pred, starts_with("X")) %>%
  mutate(Percentile = as.character(as.numeric(str_replace(Percentile, "X", "")) * 100))

ggplot(by_age, 
       aes(x = age, y = response)) + 
  geom_jitter(height = 0, width = 0, alpha = .1) +  # was width = 0.2 and alpha 0.3
  geom_line(data = preds, aes(x = age, y = pred, col = Percentile, group = Percentile)) + 
  ylim(0,nrow(milestones)) + 
  xlim(0,55) + 
  ylab("Total milestones") + 
  xlab("Age (in months)") + 
  ggthemes::scale_color_solarized() + 
  theme(legend.position = "bottom", 
        legend.title = element_text(size = 6),
        legend.text = element_text(size=6))
```

# Empirical assessment of the dimensionality of child development

We frame the assessment of the dimensionality of child development as a model comparison question. 

## Models

Item response theory offers a suite of models with which to model item response data. We adopt the notation used in @chalmers2012mirt. Let $i = 1, \ldots, I$ represent the distinct children and $j = 1, \ldots, J$ the developmental milestones. The Kinedu item response data is stored in a matrix, $y$, where element $y_{ij}$ denotes if the $i$th child has or has not achieved the $j$th developmental milestone as reported by their parent/guardian. Each model represents the $i$th child's development using $m$ latent factors $\boldsymbol{\theta}_{i}=(\theta_1, \dots, \theta_m)$. The $j$th milestone's discriminations (i.e. slopes) $\boldsymbol{a_j}=(a_1, \dots, a_m)$ capture the latent factor loadings onto that milestone. 

We fit four two-parameter logistic (2PL) models where a child’s development is represented by $m = 1, \ m = 2, \ m = 3, \ m = 4$ and $m = 5$ latent factors. Hereafter, we, for example, refer to a 2PL model with $m = 4$ latent factors as a 4F 2PL model. According to the 2PL model, the probability of a child having achieved a developmental milestone is
$$
P(y_{ij} = 1 | \boldsymbol{\theta_i}, \boldsymbol{a_j}, b_j) = \sigma(\boldsymbol{a}_{j}^{\top}\boldsymbol{\theta_i} + b_j)
$$
where $b_j$ is the milestone easiness (i.e. intercept) and $\sigma(x) = \frac{e^x}{e^x + 1}$ is the standard logistic function. We also fit a 1F Rasch model where each of the discriminations is fixed to 1. As an example, Figure \ref{fig:icc} shows item characteristic curves from 1F 2PL model for the items in Table \ref{tab:examples}. Item characteristic curves show how $P(y_{ij} = 1)$ changes as $\theta_i$ changes for a particular item. These curves reveal that most children babbling and babbling is unrelated with development. On the other hand, finding objects on the floor is highly related to development with most children with $\theta_i$ greater than -1.5 having reached this milestone. 

The 2PL models learn the latent factor structure entirely from the data, making them exploratory. The bifactor model offers an alternative specification where each milestone loads onto a general factor $\theta_0$ and a specific factor $\theta_s$ [@cai2011generalized]. The assignment of each developmental milestone to its specific factor is an opportunity to specify the latent factor structure, making the model confirmatory as opposed to exploratory. We map each milestone to its specific factor according to the four developmental milestone groups shown in Table \ref{tab:examples}. For the bifactor model, the probability of a child having achieved a developmental milestone is 
$$
P(y_{ij} = 1 | \theta_0, \theta_s, a_0, a_s) = \sigma(a_0\theta_0 + a_s\theta_s + b_j).
$$

```{r icc, fig.cap = "Example item characteristic curves. Babbling is unrelated to a child's development whereas finding objects on the floor is highly related to development."}
library(mirt)

# mirts <- read_rds(here::here("02_mirts.rds"))
mirts <- read_rds(here::here("02_mirts_2_add_5.rds"))

mod <- mirts$model_full[[2]]

traceline <- NULL

a <- which("abs_183" == colnames(d_mat))
b <- which("babbling_23" == colnames(d_mat))
c <- which("balance_708" == colnames(d_mat))
d <- which("dindep_78" == colnames(d_mat))

num <- 1
for(i in c(a, b, c, d)){
  extr.2 <- extract.item(mod, i)
  Theta <- matrix(seq(-4,4, by = .1))
  traceline[[num]] <- probtrace(extr.2, Theta)
  num = num + 1
}

# rename list
names(traceline) <- 
  c(
    "Finds objects on the floor", 
    "Babbles to imitate conversations", 
    "Stands on their toes", 
    "Complains when play is interrupted"
  )

# rbind traceline
traceline.df <- do.call(rbind, traceline)

# create item names length based on length of theta provided
item <- rep(names(traceline),each=length(Theta))

# put them all together into a dataframe
l.format <- cbind.data.frame(Theta, item, traceline.df)

l.format$item<-as.factor(l.format$item)
aux<-l.format %>%
  group_by(item) %>%
  slice(which.min(abs(P.1-0.5))) # We are only using the P.1 column (dichotomous)

aux<-aux[order(aux$Theta),]
ord<-as.integer(aux$item)
l.format$item = factor(l.format$item,levels(l.format$item)[ord])

# plot chart
l.format %>% 
  as_tibble() %>% 
  ggplot(aes(Theta, P.1)) + 
  geom_line() + 
  facet_wrap(~ item) +
  xlab(expression(theta)) + 
  ylab("Probability of milestone") + 
  theme_classic(base_size = 6)
```


## Model comparison {#modelcompare}

Model comparison in IRT typically uses information criterion such as AIC and BIC [@maydeu2013goodness]. However, these methods are not guaranteed to work with modest sample sizes or misspecification [@mcdonald1995goodness]. Instead, we prefer a marginalized version of cross-validation. In essence, we partition the data into folds based on the children (i.e. the rows of the item response matrix). Then for each fold, we estimate the item parameters using all but that fold, and calculate the likelihood of that fold by integrating over $g(\theta)$. 

Mathematically and following notation similar to @vehtari2017practical, we partition the data into $K$ subsets $y^{(k)}$ for $k = 1, \dots, K$. Each model is fit separately to each training set $y^{(-k)}$ yielding item parameter estimates which we compactly denote $\Psi_j^{(-k)}$. The predictive (i.e. out-of-sample or cross-validated) likelihood of $y^{(k)}$ is

$$
p(y^{(k)} | y^{(-k)}) = \prod_{i \in i^{(k)}}^{I} \int_\theta \prod_{j=1}^{J} \hat{\text{Pr}}(y_{ij}^{(k)} | \Psi_j^{(-k)}, \theta) g(\theta)d\theta.
$$

The ultimate quantity of interest for each model is the log predictive likelihood for the entire item response matrix, which is defined as

$$
\text{lpl } y = \sum_{k = 1}^{K} \log p(y^{(k)} | y^{(-k)}).
$$

## Results

Table \ref{tab:results} shows the number of parameters, the in-sample log likelihood (which neccessarily increases with more parameters), and the $\text{lpl } y$ defined in the [model comparison section](#modelcompare). The 4F 2PL model performs best which is evidence that child development between the ages of 2 and 55 months follows a multidimensional path. 

Computing is done in R [@rcore], model fitting in the R package mirt [@chalmers2012mirt], and data wrangling/visualization in the set of R packages known as the tidyverse [@tidy].

```{r results}
# will need latek in kables:
# https://stackoverflow.com/questions/49416492/latex-formulas-or-symbols-in-table-cells-using-knitr-and-kableextra-in-r-markdow

bifactor <- read_rds(here::here("02_bifactors.rds"))

full <-
    bind_rows(mirts, bifactor) %>%
    rename(out_of_sample = ll_person_item) %>%
    mutate(
        in_sample = exp(log_lik / nrow(d_mat))^(1/ncol(d_mat))
    ) %>%
    mutate(
        oos =
            splits_with_log_lik %>% map_dbl(~ sum(.$log_lik_test))
    ) %>%
    select(
        factors, itemtype, in_log_lik = log_lik, in_p = in_sample,
        out_log_lik = oos, out_p = out_of_sample, model_full, fscores, splits_with_log_lik)

full %>%
    mutate(npars = model_full %>% map_int(~ .@Model$nestpars)) %>%
    arrange(npars) %>%
    mutate(model = c("1F Rasch", "1F 2PL", "2F 2PL", "Bifactor", "*3F 2PL*", "4F 2PL", "5F 2PL")) %>%
    select(model, parameters = npars, `log-likelihood (in-sample)` = in_log_lik, `lpl y (out-of-sample)` = out_log_lik) %>% 
  knitr::kable("latex", caption = "Model performance: The 3F 2PL performs best as measured by lpl y") %>% 
    kableExtra::kable_styling(font_size = 8, latex_options = "hold_position")
```

## Understanding the latent factor structure

To understand each of the three factors in the best performing model, we fit the model to the the full dataset. We then estimate the factor loadings (i.e. discriminations or slopes) using a varimax rotation. The varimax rotation results in orthogonal and, therefore, more interpretable factors [@kaiser1959computer]. Figure \ref{fig:factorloadings} shows the distribution of factor loadings for each group on each of the three factors. The first factor load mainly on cognitive and linguistic milestones. The second factor is a combination of each of the groups with the strongest loadings on the physical and social & emotional milestones. The third mainly load positively on linguistic milestones and, interestingly, negatively on physical milestones. 

```{r, include = FALSE}
mod3 <- full$model_full[[4]]
mod3_summary <- summary(mod3, rotate = "varimax")
```

```{r factorloadings, fig.cap = 'Factor loadings by group'}
mod3_summary_with_areas <-
    mod3_summary$rotF %>%
    as_tibble() %>%
    mutate(paste = row.names(mod3_summary$rotF)) %>%
    left_join(areas)

mod3_summary_with_areas %>%
    select(Group = area, F1, F2, F3) %>%
    rename(`Factor 1` = F1, `Factor 2` = F2, `Factor 3` = F3) %>% 
    gather(var, val, -Group) %>%
    mutate(val = -val) %>%
    ggplot(aes(x = val, fill = Group)) +
    ggridges::geom_density_line(alpha = 0.5) +
    facet_wrap(~ var, ncol = 1) +
    labs(
        x = "Factor loading (i.e. discrimination or slope)",
        y = "Density"
    ) +
    theme_classic(base_size = 8) + 
    theme(legend.position = "bottom", 
          legend.title = element_text(size = 6),
          legend.text = element_text(size=6),
          legend.key.size = unit(0.2, "cm"))
```

We also estimate the factor scores for each child using expected a posteriori (EAP) with a three dimensional standard normal distribution [@embretson2013item].  Figure \ref{fig:factorscores} shows the relationship between age and factor score for each factor. The first factor, perhaps unsurprisingly, has a high correlation (r = 0.90) with age. The second factor has a strong association with age from 2 to 16 months but thereafter is unrelated to age. By and large, the third factor does not have any association with age.

```{r factorscores, fig.cap = 'The first factor is highly associated with age'}
f <- fscores(mod3, rotate = "varimax")

# to find that correlation of 0.9 above
# tmp <- f %>% as_tibble() %>% mutate(age = ages$age)
# cor(hi$F1, hi$age)

f %>%
    as_tibble() %>%
    mutate(age = ages$age) %>%
    rename(`Factor 1` = F1, `Factor 2` = F2, `Factor 3` = F3) %>% 
    gather(var, val, -age) %>%
    mutate(val = -val) %>%
    ggplot(aes(x = age, y = val)) +
    geom_point(alpha = 0.1) +
    facet_wrap(~ var, ncol = 1) +
    geom_smooth() +
    labs(
        x = "Age (in months)",
        y = "Factor score"
    )
```

# Dimensionality across the age-span

For the entire dataset, we’ve shown evidence that 4-factors performs best. But is this latent factor dimensionality consistent across age-span? For example, perhaps for very young children 1-factor is sufficient and then later on 2- and then 3-factors become valuable. We take two approaches to assessing the dimensionality of child development across the age-span. First, we examine the performance of each of the models by age. Second, we partition the data by age and use the same cross-validation procedure to find the best fitting model in each partition.

## Full model {#full}

Figure \ref{fig:byage} displays the mean cross-validated log likelihood for each model by age, which comes from the k-fold cross-validation described in the [model comparison](#modelcompare) section. For each student, we calculate the marginalized out-of-sample likelihood based on the item parameters $\Psi_j^{(-k)}$ from fitting the model to $y^{(-k)}$, the folds of data that does not include the student. As a reminder, students are assigned to folds randomly and not by age. 

Figure \ref{fig:byage} shows how both the 4F 2PL and bifactor models compare to the 2F 2PL model in terms of cross-validated log likelihood for each age. The 2F 2PL outperforms both models for children younger than 7 months old. For children older than 11 months old both the 4F 2PL and bifactor models outperform the 2F 2PL model with the 4F 2PL model tending to perform best. Interestingly, the bifactor model performs more similarly across the age-span to the 4F 2PL than the 2F 2PL despite having a similar number of parameters to the 2F 2PL. 

```{r byage, fig.cap = 'Comparing the 4F 2PL and Bifactor models to the 2F 2PL'}
read_rds(here::here("03_model_by_age.rds")) %>%
    filter(model %in% c("2F 2PL", "4F 2PL", "Bifactor")) %>%
    mutate(model = factor(model, levels = c("2F 2PL", "Bifactor", "4F 2PL"))) %>% 
    select(model, oos) %>%
    unnest(oos) %>%
    mutate(oos = log(oos)) %>%
    group_by(model, age) %>%
    summarize(m = mean(oos)) %>%
    ungroup() %>%
    spread(model, m) %>% 
    mutate(`4F 2PL` = `4F 2PL` - `2F 2PL`, Bifactor = Bifactor - `2F 2PL`) %>% 
    select(-`2F 2PL`) %>% 
    gather(Model, m, -age) %>% 
    ggplot(aes(x = age, y = m, color = Model)) +
    geom_point(size = 0.75) +
    geom_path(size = 0.35) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(x = "Age (in months)", y = "Mean difference in log likelihood") +
    theme_classic(base_size = 10) + 
    theme(legend.position = "bottom", 
            legend.title = element_text(size = 8),
            legend.text = element_text(size = 8),
            legend.key.size = unit(0.3, "cm"))
```

## Age-partitioned models

As another method of examining the dimensionality of child development across the age span, we create four partitions of the data based on the ages of the children. We then cross-validate the 2PL models independently in each partition. This allows us to examine the dimensionality for each age group separately. For each age partition, we drop milestones where less than 2.5% or greater than 97.5% of children have reached the milestone. Dropping milestones is done because these milestones do not contain much information and make IRT models less stable. This process results in, for example, 432 children and 359 milestones in the 13-24 month old partition.

Figure \ref{fig:partage} shows the results of this analysis. Consistent with our findings in the [previous section](#full), the best fitting model contains a lower dimensional factor structure for younger children. The best fitting model is the 2F 2PL for the partition of data containing children two to 12 months old, whereas the best fitting model is the 3F 2PL for the partitions containing older children.

```{r partage, fig.cap = '2F 2PL best for young kids; 3F 2PL best for older kids'}
splits_by_age <- read_rds(here::here("archived/13_splits_by_age.rds"))

add_lltest <- function(a){
  a %>% 
  mutate(
    log_lik_test = 
      splits_with_log_lik %>% 
      map_dbl(~ sum(.$log_lik_test))
  )
}

b <- splits_by_age %>% 
  mutate(models2 = models %>% map(add_lltest))

tibble(
  years = c("2-12 months", "13-24 months", "25-36 months", "37+ months")
) %>% 
  mutate(
    kids = splits_by_age$d_mat_filter %>% map_int(nrow),
    items = splits_by_age$d_mat_filter %>% map_int(ncol),
    m  = b$models2
  ) %>% 
  unnest() %>% 
  select(years, kids, items, factors, itemtype, log_lik, log_lik_test) %>% 
  mutate(var = as_factor(paste0(years, " ", kids, " kids", " ", items, " items"))) %>% 
  filter(itemtype == "2PL") %>% 
  ggplot(aes(x = factors, y = log_lik_test)) +
  geom_point() +
  geom_line(aes(group = years)) +
  facet_wrap(~ var, ncol = 1, scales = "free") +
  labs(
    x = "m-factor 2PL model",
    y = "Cross-validated log likelihood"
  ) +
  theme_classic(base_size = 8)
```

# Discussion

Is child development a singlue unified process or a host of different processes? Piaget famously proposed a stage theory but did not have the data with which to offer an empirical answer. We used the Mexico-based child development app, Kinedu, where parents report the developmental milestones that their child has reached as a source of data. We measured the dimensionality of child development in this data by comparing item-response models that varied in how they represented the latent factor structure of development. We found that the 3F 2PL model performed best as measured by cross-validated log-likelihood, $\text{lpl } y$. This is evidence that child development from 0 - 55 months of age has at least three dimensions. In terms of milestones, the first dimension loaded highly on cognitive and linguistic milestones. The second dimension focused on physical and social & emotional milestones. The third dimension was positively associated with linguistic milestones and negatively associated with physical milestones. In terms of children, the first dimension was highly associated with age whereas the second and third dimensions were mostly unassociated with age. We also found that the dimensionality of development grows over the age-span.

The main limitation of this study is that our data is from a very specific population of children and parents: Namely middle-class Mexican families where the parents both use Kinedu and have the patience to answer over 400 developmental milestone questions. Future work should apply the same methodology to a variety of similar datasets that target other populations. An additional limitation is that all of our data comes from parents. It's impossible for us to be sure that we've measured true variation in child development as opposed to variation in how students perceive or report their child's development. In general, parent reporting is incredibly common but can have significant limitations [@wordbank; @tomasello1994instrument; @feldman2000measurement]. Ideally, future work will include datasets that do not gather data from parent reporting. 

Future work should also look to understand practical implications of dimensionality. Should parents notice multiple dimensions or will they mostly notice only the first dimension? Do the multiple dimensions have implications for how we should intervene if a child is not developing properly? For example, perhaps the best intervention for developmental delay on the second dimension is quite different from the best intervention for developmental delay on the first dimension.

# Acknowledgements

We'd like to thank Kinedu for providing the data that made this research possible. We'd also like to thank George Kachergis and Alex Carstensen for insightful comments on early versions of this paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
