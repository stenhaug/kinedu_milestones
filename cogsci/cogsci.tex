% Template for Cogsci submission with R Markdown

% Stuff changed from original Markdown PLOS Template
\documentclass[10pt, letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{float}
\usepackage{caption}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}

% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% hyperref package, useful for hyperlinks
\usepackage{hyperref}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% Sweave(-like)
\usepackage{fancyvrb}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}
\DefineVerbatimEnvironment{Code}{Verbatim}{}
\DefineVerbatimEnvironment{CodeInput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{CodeOutput}{Verbatim}{}
\newenvironment{CodeChunk}{}{}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{apacite}

% KM added 1/4/18 to allow control of blind submission
\cogscifinalcopy

\usepackage{color}

% Use doublespacing - comment out for single spacing
%\usepackage{setspace}
%\doublespacing


% % Text layout
% \topmargin 0.0cm
% \oddsidemargin 0.5cm
% \evensidemargin 0.5cm
% \textwidth 16cm
% \textheight 21cm

\title{The latent factor structure of child development}

\usepackage{amsmath}
\usepackage{bm}
\usepackage{xcolor}
\newcommand\myworries[1]{\textcolor{red}{#1}}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\author{Anonymous Cogsci Submission}

\begin{document}

\maketitle

\begin{abstract}
\myworries{to do}

\textbf{Keywords:}
child development; milestones; item response theory; model comparison
\end{abstract}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\textcolor{red}{to do}

\hypertarget{data}{%
\section{Data}\label{data}}

A child's development can be thought of as the set of developmental
milestones that they have reached at a particular point in time. This
conceptualization results in data with the same structure as the item
response data common to educational measurement. In education, item
response data is most typically students responding to test items (i.e.,
questions) and, in the dichotomous case, getting each question either
correct or incorrect. In the context of child development, the child is
the ``student,'' and each developmental milestone is the ``item.''

We use Kinedu, a Mexico-based child development app, as a source for
this type of data. When parents first start using the Kinedu app, they
are asked a series of questions about which developmental milestones
their child has reached. We consider the 1946 children between 2 and 55
months of age whose parents responded to all 414 of the developmental
milestones. Each developmental miletone on Kinedu is mapped to a
milestone group: physical, cognitive, linguistic, or social \&
emotional. Table \ref{tab:examples} shows the number of developmental
milestones in each group along with an example milestone translated to
English.

\begin{CodeChunk}
\begin{table}[!h]

\caption{\label{tab:examples}Developmental milestone groups and examples}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{l|r|l}
\hline
Group & Count & Example milestone\\
\hline
Physical & 180 & Stands on their toes\\
\hline
Cognitive & 100 & Finds objects on the floor\\
\hline
Linguistic & 75 & Babbles to imitate conversations\\
\hline
Social \& Emotional & 59 & Complains when play is interrupted\\
\hline
\end{tabular}
\end{table}

\end{CodeChunk}

Figure \ref{fig:growth} shows the age (in months) and number of
developmental milestones for each child. At 12 months old, most children
have reached about 200 developmental milestones. At 24 months old, most
children have reached about 300 developmental milestones. Finally, at 48
months old, most children have reached about 375 of the 414
developmental milestones.

\textcolor{red}{probably should describe where}
\textcolor{red}{the percentile curves come from}

\begin{CodeChunk}
\begin{figure}[tb]
\includegraphics{figs/growth-1} \caption[Number of milestones by age]{Number of milestones by age}\label{fig:growth}
\end{figure}
\end{CodeChunk}

\hypertarget{empirical-assessment-of-the-dimensionality-of-child-development}{%
\section{Empirical assessment of the dimensionality of child
development}\label{empirical-assessment-of-the-dimensionality-of-child-development}}

We frame the assessment of the dimensionality of child development as a
model comparison question.

\hypertarget{models}{%
\subsection{Models}\label{models}}

Item response theory offers a suite of models with which to model item
response data. We adopt the notation used in Chalmers \& others (2012).
Let \(i = 1, \ldots, I\) represent the distinct children and
\(j = 1, \ldots, J\) the developmental milestones. The Kinedu item
response data is stored in a matrix, \(y\), where element \(y_{ij}\)
denotes if the \(i\)th child has or has not achieved the \(j\)th
developmental milestone as reported by their parent/guardian. Each model
represents the \(i\)th child's development using \(m\) latent factors
\(\boldsymbol{\theta}_{i}=(\theta_1, \dots, \theta_m)\). The \(j\)th
milestone's discriminations (i.e.~slopes)
\(\boldsymbol{a_j}=(a_1, \dots, a_m)\) capture the latent factor
loadings onto that milestone.

We fit four two-parametric logistic (2PL) models where a child's
development is represented by \(m = 1, \ m = 2, \ m = 3,\) and \(m = 4\)
latent factors. Hereafter, we, for example, refer to a 2PL model with
\(m = 4\) latent factors as a 4F 2PL model. According to the 2PL model,
the probability of a child having achieved a developmental milestone is
\[
P(y_{ij} = 1 | \boldsymbol{\theta_i}, \boldsymbol{a_j}, b_j) = \sigma(\boldsymbol{a}_{j}^{\top}\boldsymbol{\theta_i} + b_j)
\] where \(b_j\) is the milestone easiness (i.e.~intercept) and
\(\sigma(x) = \frac{e^x}{e^x + 1}\) is the standard logistic function.
We also fit a 1F Rasch model where each of the discriminations is fixed
to 1.

The 2PL models learn the latent factor structure entirely from the data,
making them exploratory. The bifactor model offers an alternative
specification where each milestone loads onto a general factor
\(\theta_0\) and a specific factor \(\theta_s\) (Cai, Yang, \& Hansen,
2011). The assignment of each developmental milestone to its specific
factor is an opportunity to specify the latent factor structure, making
the model confirmatory as opposed to exploratory. We map each milestone
to its specific factor according to the four developmental milestone
groups shown in Table \ref{tab:examples}. For the bifactor model, the
probability of a child having achieved a developmental milestone is \[
P(y_{ij} = 1 | \theta_0, \theta_s, a_0, a_s) = \sigma(a_0\theta_0 + a_s\theta_s + b_j).
\]

\hypertarget{modelcompare}{%
\subsection{Model comparison}\label{modelcompare}}

Model comparison in IRT typically uses information criterion such as AIC
and BIC (Maydeu-Olivares, 2013). However, these methods are not
guaranteed to work with modest sample sizes or misspecification
(McDonald \& Mok, 1995). Instead, we prefer a marginalized version of
cross-validation. In essence, we partition the data into folds based on
the children (i.e.~the rows of the item response matrix). Then for each
fold, we estimate the item parameters using all but that fold, and
calculate the likelihood of that fold by integrating over \(g(\theta)\).

Mathematically and following notation similar to Vehtari, Gelman, \&
Gabry (2017), we partition the data into \(K\) subsets \(y^{(k)}\) for
\(k = 1, \dots, K\). Each model is fit separately to each training set
\(y^{(-k)}\) yielding item parameter estimates which we compactly denote
\(\Psi_j^{(-k)}\). The predictive (i.e.~out-of-sample or
cross-validated) likelihood of \(y^{(k)}\) is

\[
p(y^{(k)} | y^{(-k)}) = \prod_{i \in i^{(k)}}^{I} \int_\theta \prod_{j=1}^{J} \hat{\text{Pr}}(y_{ij}^{(k)} | \Psi_j^{(-k)}, \theta) g(\theta)d\theta.
\]

The ultimate quantity of interest for each model is the log predictive
likelihood for the entire item response matrix, which is defined as

\[
\text{lpl } y = \sum_{k = 1}^{K} \log p(y^{(k)} | y^{(-k)}).
\]

\hypertarget{results}{%
\subsection{Results}\label{results}}

\textcolor{red}{fascinating that dropping 1 month olds}
\textcolor{red}{changed the winner from 3F to 4F}

Table \ref{tab:results} shows the number of parameters, the in-sample
log likelihood (which neccessarily increases with more parameters), and
the \(\text{lpl } y\) defined in the
\protect\hyperlink{modelcompare}{model comparison section}. The 4F 2PL
model performs best which is evidence that child development between the
ages of 2 and 55 months follows a multidimensional path.

\textcolor{red}{need to tie results to literature}

Computing is done in R (R Core Team, 2019), model fitting in the R
package mirt (Chalmers \& others, 2012), and data
wrangling/visualization in the set of R packages known as the tidyverse
(Wickham, 2017).

\textcolor{red}{think about presentation of this table.}
\textcolor{red}{is it worth displaying in sample numbers?}
\textcolor{red}{would it be better as a graph?}

\begin{CodeChunk}
\begin{table}[!h]

\caption{\label{tab:results}Model performance: The 4F 2PL performs best}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}[t]{l|r|r|r}
\hline
model & npars & in\_log\_lik & lpl y (out-of-sample)\\
\hline
1F Rasch & 415 & -254983.9 & -255443.5\\
\hline
1F 2PL & 828 & -222073.0 & -223072.0\\
\hline
2F 2PL & 1241 & -212957.9 & -214498.2\\
\hline
Bifactor & 1242 & -210030.2 & -211682.2\\
\hline
3F 2PL & 1653 & -208887.6 & -210943.4\\
\hline
*4F 2PL* & 2064 & -208124.1 & -210793.5\\
\hline
\end{tabular}
\end{table}

\end{CodeChunk}

\hypertarget{understanding-the-latent-factor-structure}{%
\subsection{Understanding the latent factor
structure}\label{understanding-the-latent-factor-structure}}

\textcolor{red}{section is written as if 3F is winner}
\textcolor{red}{may need to edit to 4F}

To understand each of the three factors in the best performing model, we
fit the model to the the full dataset. We then estimate the factor
loadings (i.e.~discriminations or slopes) using a varimax rotation. The
varimax rotation results in orthogonal and, therefore, more
interpretable factors (Kaiser, 1959). Figure \ref{fig:factorloadings}
shows the distribution of factor loadings for each group on each of the
three factors. The first factor load mainly on cognitive and linguistic
milestones. The second factor is a combination of each of the groups
with the strongest loadings on the physical and social \& emotional
milestones. The third mainly load positively on linguistic milestones
and, interestingly, negatively on physical milestones.

\begin{CodeChunk}
\begin{figure}[tb]
\includegraphics{figs/factorloadings-1} \caption[Factor loadings by group]{Factor loadings by group}\label{fig:factorloadings}
\end{figure}
\end{CodeChunk}

We also estimate the factor scores for each child using expected a
posteriori (EAP) with a three dimensional standard normal distribution
(Embretson \& Reise, 2013). Figure \ref{fig:factorscores} shows the
relationship between age and factor score for each factor. The first
factor, perhaps unsurprisingly, has a high correlation (r = 0.90) with
age. The second factor has a strong association with age from 2 to 16
months but thereafter is unrelated to age. By and large, the third
factor does not have any association with age.

\begin{CodeChunk}
\begin{figure}[tb]
\includegraphics{figs/factorscores-1} \caption[The first factor is highly associated with age]{The first factor is highly associated with age}\label{fig:factorscores}
\end{figure}
\end{CodeChunk}

\hypertarget{dimensionality-across-the-age-span}{%
\section{Dimensionality across the
age-span}\label{dimensionality-across-the-age-span}}

For all of the data, we've shown evidence that 4-factors performs best.
But is this latent factor dimensionality consistent across age-span? For
example, perhaps for very young children 1-factor is sufficient and then
later on 2- and then 3-factors become valuable. We take two approaches
to assessing the dimensionality of child development across the
age-span. First, we examine the performance of each of the models by
age. Second, we partition the data by age and use the same
cross-validation procedure to find the best fitting model in each
partition.

\hypertarget{full}{%
\subsection{Full model}\label{full}}

\textcolor{red}{figure currently shows up at end of paper.}
\textcolor{red}{if we go with this graph,}
\textcolor{red}{probably want more smoothing}

Figure \ref{fig:byage} displays the mean cross-validated log likelihood
for each model by age, which comes from the k-fold cross-validation
described in the \protect\hyperlink{modelcompare}{model comparison}
section. For each student, we calculate the marginalized out-of-sample
likelihood based on the item parameters \(\Psi_j^{(-k)}\) from fitting
the model to \(y^{(-k)}\), the folds of data that does not include the
student. As a reminder, students are assigned to folds randomly and not
by age.

Figure \ref{fig:byage} shows that cross-validated log likelihood is
highest for very young (less than 8 months old) and older (greater than
48 months old) children. This is not surprising as the number of
milestones for each of these age groups is relatively close to 0\% and
100\% respectively. More importantly, we see that the 2F 2PL model
performs best for children two to six months old. The 2F 2PL model
performs as well as the 4F 2PL model for children from six months old to
11 months old. For children older than 11 months old, the 4F 2PL model
tends to perform best. Interestingly, the bifactor model performs more
similarly across the age-span to the 4F 2PL than the 2F 2PL despite
having a similar number of parameters to the 2F 2PL.

\begin{CodeChunk}
\begin{figure}[tb]
\includegraphics{figs/byage-1} \caption[More flexible models perform better at older ages]{More flexible models perform better at older ages}\label{fig:byage}
\end{figure}
\end{CodeChunk}

\hypertarget{age-partitioned-models}{%
\subsection{Age-partitioned models}\label{age-partitioned-models}}

\textcolor{red}{figure currently shows up at end of paper.}
\textcolor{red}{need to add in 4F models}

As another method of examining the dimensionality of child development
across the age span, we create four partitions of the data based on the
ages of the children. We then cross-validate the 2PL models
independently in each partition. This allows us to examine the
dimensionality for each age group separately. For each age partition, we
drop milestones where less than 2.5\% or greater than 97.5\% of children
have reached the milestone. Dropping milestones is done because these
milestones do not contain much information and make IRT models less
stable. This process results in, for example, 432 children and 359
milestones in the 13-24 month old partition.

\textcolor{red}{should we note (or sensitivity check)}
\textcolor{red}{the tendency smaller datasets}
\textcolor{red}{to prefer less flexible models?}

Figure \ref{fig:partage} shows the results of this analysis. Consistent
with our findings in the \protect\hyperlink{full}{previous section}, the
best fitting model contains a lower dimensional factor structure for
younger children. The best fitting model is the 2F 2PL for the partition
of data containing children two to 12 months old, whereas the best
fitting model is the 3F 2PL for the partitions containing older
children.

\begin{CodeChunk}
\begin{figure}[tb]
\includegraphics{figs/partage-1} \caption[2F 2PL best for young kids]{2F 2PL best for young kids; 3F 2PL best for older kids}\label{fig:partage}
\end{figure}
\end{CodeChunk}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\textcolor{red}{to do}

\hypertarget{acknowledgements}{%
\section{Acknowledgements}\label{acknowledgements}}

We'd like to thank Kinedu for providing the data that made this research
possible.

\hypertarget{references}{%
\section{References}\label{references}}

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}

\noindent

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-cai2011generalized}{}%
Cai, L., Yang, J. S., \& Hansen, M. (2011). Generalized full-information
item bifactor analysis. \emph{Psychological Methods}, \emph{16}(3), 221.

\leavevmode\hypertarget{ref-chalmers2012mirt}{}%
Chalmers, R. P., \& others. (2012). Mirt: A multidimensional item
response theory package for the r environment. \emph{Journal of
Statistical Software}, \emph{48}(6), 1--29.

\leavevmode\hypertarget{ref-embretson2013item}{}%
Embretson, S. E., \& Reise, S. P. (2013). \emph{Item response theory}.
Psychology Press.

\leavevmode\hypertarget{ref-kaiser1959computer}{}%
Kaiser, H. F. (1959). Computer program for varimax rotation in factor
analysis. \emph{Educational and Psychological Measurement},
\emph{19}(3), 413--420.

\leavevmode\hypertarget{ref-maydeu2013goodness}{}%
Maydeu-Olivares, A. (2013). Goodness-of-fit assessment of item response
theory models. \emph{Measurement: Interdisciplinary Research and
Perspectives}, \emph{11}(3), 71--101.

\leavevmode\hypertarget{ref-mcdonald1995goodness}{}%
McDonald, R. P., \& Mok, M. M.-C. (1995). Goodness of fit in item
response models. \emph{Multivariate Behavioral Research}, \emph{30}(1),
23--40.

\leavevmode\hypertarget{ref-rcore}{}%
R Core Team. (2019). \emph{R: A language and environment for statistical
computing}. Vienna, Austria: R Foundation for Statistical Computing.
Retrieved from \url{https://www.R-project.org/}

\leavevmode\hypertarget{ref-vehtari2017practical}{}%
Vehtari, A., Gelman, A., \& Gabry, J. (2017). Practical bayesian model
evaluation using leave-one-out cross-validation and waic.
\emph{Statistics and Computing}, \emph{27}(5), 1413--1432.

\leavevmode\hypertarget{ref-tidy}{}%
Wickham, H. (2017). \emph{Tidyverse: Easily install and load the
'tidyverse'}. Retrieved from
\url{https://CRAN.R-project.org/package=tidyverse}

\bibliographystyle{apacite}


\end{document}
