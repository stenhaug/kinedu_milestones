---
title: "Kinedu Milestone Report V2"
author: "Mike Frank"
date: "Rendered `r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
---


# Intro

```{r}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, cache=TRUE, message=FALSE, 
                      sanitize = TRUE)
```

```{r}
library(tidyverse)
# library(stringr)
# library(ggthemes)
library(quantregGrowth)
# library(forcats)
# library(purrr)
# library(ggrepel)
# library(DT)
library(mirt)
select <- dplyr::select
source("predictQR_fixed.R")
# theme_set(theme_few())
```

Read data. 

```{r}
fix_names <- function(x) ifelse(x == "", paste0("X__", 1:length(x) - 1), x)

d_raw <- 
  readxl::read_xlsx(
    "data/norming2/Kinedu Norming Survey Raw Data - May 15 2018.xlsx", 
    .name_repair = fix_names
  )
```

Get milestone labels. 

```{r}
milestones <- 
  d_raw %>%
  select(abs_183:color_679) %>%
  slice(3) %>%
  gather(code, name) %>%
  mutate(short_name = str_sub(name, start = 0, end = 40), 
         code = str_replace(code, "^d_","d"),
         code = str_replace(code, "^e_","")) %>%
  mutate(code2 = code) %>%
  separate(code2, into = c("category","number")) %>%
  select(-number) 

n_milestones <- nrow(milestones)
```

Wrangle data. 

```{r}
d <- d_raw %>%
  mutate(age = as.numeric(X__422), 
         gestation = as.numeric(X__3),
         kinder = as.numeric(X__4),
         diagnosis = as.numeric(X__1), 
         id = `Nombre variable`) %>%
  slice(4:n()) %>% # drop two top label rows. 
  select(-starts_with("X"), -`Nombre variable`) %>%
  gather(code, response, abs_183:color_679) %>%
  mutate(code = str_replace(code, "^d_","d"),
         code = str_replace(code, "^e_",""),
         code2 = code) %>%
  separate(code2, into = c("category","number")) %>%
  select(-number) %>%
  mutate(response = as.numeric(response))
```

There are `r n_milestones` milestones and `r length(unique(d$id))` children. 

# Descriptives

We begin with some descriptions of the dataset. The age distribution is very consistent, with some underrepresentation at the low end. 

```{r}
by_age <- d %>%
  group_by(id) %>%
  summarise(age = age[1], 
            response = sum(response))

ggplot(by_age, aes(x = age)) + 
  geom_histogram(stat = "count")
```

# Growth Curves

We next turn to an analysis of individual children's total milestones achieved. This analysis yields classic growth curves including percentiles. It's clear from looking at these curves that 1) overall the survey is working well, but 2) there is some overreporting by parents of quite young infants. This second observations refers to the group of points well above the percentile curves. They seem like they are misinterpreting the task. 

```{r}
taus <-  c(0.1, 0.25, 0.5, 0.75, 0.9)

mod <- gcrq(formula = response ~ ps(age, monotone = 1, lambda = 1000), 
     tau = taus, data = by_age)

ages <- 1:48
newdata <- data.frame(age = ages)

preds <- predictQR_fixed(mod, newdata = newdata) %>%
  data.frame %>%
  mutate(age = ages) %>%
  gather(percentile, pred, starts_with("X")) %>%
  mutate(percentile = as.character(as.numeric(str_replace(percentile, "X", "")) * 100))
```

Now plot model predictions.

```{r}
ggplot(by_age, 
       aes(x = age, y = response)) + 
  geom_jitter(height = 0, width = .2, alpha = .3) + 
  geom_line(data = preds, aes(x = age, y = pred, col = percentile, group = percentile)) + 
  ylim(0,n_milestones) + 
  xlim(0,48) + 
  ylab("Total milestones") + 
  xlab("Age (months)") + 
  ggthemes::scale_color_solarized() + 
  theme(legend.position = "bottom")
```

It seems pretty obvious that there are some children here who hsve parents that are really radically under/over reporting (mostly over-reporting). 

Let's remove these more or less by hand. We'll just remove all the `age = 0` kids for now. 

```{r}
excl <- by_age %>%
  filter(age == 0) %>%
  pull(id)

by_age <- filter(by_age, !(id %in% excl))
d <- filter(d, !(id %in% excl))
```

Replot. 

```{r}
mod <- gcrq(formula = response ~ ps(age, monotone = 1, lambda = 1000), 
     tau = taus, data = by_age)

ages <- 1:48
newdata <- data.frame(age = ages)

preds <- predictQR_fixed(mod, newdata = newdata) %>%
  data.frame %>%
  mutate(age = ages) %>%
  gather(percentile, pred, starts_with("X")) %>%
  mutate(percentile = as.character(as.numeric(str_replace(percentile, "X", "")) * 100))

ggplot(by_age, 
       aes(x = age, y = response)) + 
  geom_jitter(height = 0, width = .2, alpha = .3) + 
  geom_line(data = preds, aes(x = age, y = pred, col = percentile, group = percentile)) + 
  ylim(0,n_milestones) + 
  xlim(0,48) + 
  ylab("Total milestones") + 
  xlab("Age (months)") + 
  ggthemes::scale_color_solarized() + 
  theme(legend.position = "bottom")
```
Looks generally great, with the exception of a few outliers. We could trim these more carefully but for now let's just live with them. 

# Milestone Analysis

In this section we focus on individual milestones and their growth pattern. 

Now let's look at sample milestone trajectories. (Note that I'm going to have to truncate a lot of milestone names to get them to fit.)  Here are a few.

```{r}
ms <- d %>%
  filter(code %in% unique(d$code)[1:16]) %>%
  left_join(milestones) %>%
  group_by(age, short_name) %>%
  summarise(mean = mean(response), 
            n = n())

ggplot(ms, aes(x = age, y = mean)) + 
  geom_point(aes(size = n), alpha = .5) +
  scale_size_continuous(range = c(1, 4)) + 
  geom_smooth(se=FALSE, aes(weight = 1/n)) + 
  facet_wrap(~short_name) + 
  ylim(0,1)+
  theme(strip.text = element_text(size = 5))
```

These curves generally look very well-behaved from a random sample. 

Next, let's look at the coherence of the milestone categories. 

```{r}
mss <- d %>%
  group_by(age, category, code) %>%
  summarise(response = mean(response))

ms <- d %>%
  group_by(age, category) %>%
  summarise(response = mean(response), 
            n = n())

ggplot(ms, aes(x = age, y = response)) + 
  # geom_point(aes(size = n), alpha = .5) +
  geom_line(data = mss, aes(x = age, y = response, group=code), 
              alpha = .5, col = "black") + 
  facet_wrap(~category) + 
  geom_smooth(se=FALSE, aes(weight = 1/n)) + 
  ylim(0,1) + 
  theme(strip.text = element_text(size = 8))
```

Overall they look very coherent and consistent. These are both major improvements from the previous version. 

# Psychometric analysis

## Single factor model

Begin by fitting a 4PL model with a single $\theta$ parameter for each kid. 

```{r}
d_wide <- d %>%
  select(id, code, response) %>%
  spread(code, response)
  
d_mat <- d_wide %>%
  select(-id) %>% 
  data.frame %>%
  data.matrix

colnames(d_mat) <- sort(unique(d$code))
rownames(d_mat) <- d_wide$id

# Requires no empty rows - `personfit` doesn't work with `removeEmptyRows=TRUE` even though the model fit will work that way. 
d_mat <- d_mat[complete.cases(d_mat),]

mod_2pl <- mirt(d_mat, 1, itemtype='2PL', verbose=TRUE, TOL = 0.0001)

mod_3pl <- mirt(d_mat, 1, itemtype='3PL', verbose=TRUE, TOL = 0.0001)

mod_4pl <- mirt(d_mat, 1, itemtype='4PL', verbose=TRUE, TOL = 0.001)

anova(mod_2pl, mod_3pl)
anova(mod_4pl, mod_3pl)

mod_4pl@Fit$logLik

coefs_4pl <- as_data_frame(coef(mod_4pl, simplify = TRUE)$items) %>%
  mutate(code = rownames(coef(mod_4pl, simplify = TRUE)$items))

fscores_3pl <- data_frame(id = rownames(d_mat), 
                             ability = fscores(mod_3pl, method = "MAP")[,1])

fscores_3pl <- data_frame(id = rownames(d_mat), 
                             ability = fscores(mod_3pl, method = "EAP")[,1])

fscores_4pl <- data_frame(id = rownames(d_mat), 
                             ability = fscores(mod_4pl, method = "MAP")[,1])

save(file = "cached_data/norming2_mod_4pl.Rds", "mod_4pl","fscores_4pl", "coefs_4pl")
```

```{r}
plot(fscores_3pl$ability, fscores_4pl$ability)
```


Now examine the person-level fits. 

```{r}
kids <- full_join(fscores_4pl, by_age)

ggplot(kids, aes(x = age, y = ability)) + 
  geom_point(alpha = .1)
ggplot(kids, aes(x = age, y = response)) + 
  geom_point(alpha = .1)
```
Overall $\theta$ values appear to be correlated with age and to have relatively little variance before age 2, but then have more varibility from 2 - 3 especially. 

Let's look at coefficients. 

```{r}
coefs_4pl <- left_join(coefs_4pl, milestones)

ggplot(coefs_4pl,  
       aes(x = a1, y = d, col = category)) + 
  geom_point(alpha = .6) + 
  ggrepel::geom_text_repel(data = filter(coefs_4pl, 
                                         a1 < -3.5 | d < -3),
                           aes(label = category), size = 3) + 
  scale_color_discrete(guide = FALSE) + 
  xlab("Discrimination") + 
  ylab("Difficulty")
```


```{r}
coefs_4pl <- left_join(coefs_4pl, milestones)

ggplot(coefs_4pl,  
       aes(x = g, y = u, col = category)) + 
  geom_point(alpha = .6) + 
  ggrepel::geom_text_repel(data = filter(coefs_4pl, 
                                         g > .5 | u < .5),
                           aes(label = category), size = 3) + 
  scale_color_discrete(guide = FALSE) +
  xlim(0,1) + 
  ylim(0,1) + 
  xlab("Lower Bound") + 
  ylab("Upper Bound")
```



## Multi-factor model

```{r}
mod_2f <- mirt(d_mat, 2, itemtype='4PL', verbose=TRUE, technical = list(NCYCLES = 10))

mod_2f3 <- mirt(d_mat, 2, itemtype='3PL', verbose=TRUE)

coefs_2f <- as_data_frame(coef(mod_2f, simplify = TRUE)$items) %>%
  mutate(code = rownames(coef(mod_2f, simplify = TRUE)$items))

fs <- fscores(mod_2f, method = "MAP")
fscores_2f <- data_frame(id = rownames(d_mat), 
                         t1 = fs[,1], 
                         t2 = fs[,2])

save(file = "cached_data/norming2_mod_2f.Rds", "mod_2f","fscores_2f", "coefs_2f")

```

Let's first look at structure in the kid data. 

```{r}
kids <- full_join(fscores_2f, by_age)

ggplot(kids, aes(x = t1, y = t2, col = age)) + 
  geom_point(alpha = .5) + 
  viridis::scale_color_viridis()
```

Wow, this is interesting. In the younger kids it seems very likely to be single factor with some variation (or at least there is a single principal axis. But for the older kids there is a lot of variability and structure!

```{r}
coefs_2f <- left_join(coefs_2f, milestones)

```

Let's see what this does to the items. 

```{r}
a <- ggplot(coefs_2f,  
       aes(x = a1, y = d, col = category)) + 
  geom_point(alpha = .6) + 
  ggrepel::geom_text_repel(data = filter(coefs_2f, 
                                         a1 > 0 | d < -5),
                           aes(label = category), size = 3) + 
  scale_color_discrete(guide = FALSE) + 
  xlab("Discrimination") + 
  ylab("Difficulty f1")

b <- ggplot(coefs_2f,  
       aes(x = a2, y = d, col = category)) + 
  geom_point(alpha = .6) + 
  ggrepel::geom_text_repel(data = filter(coefs_2f, 
                                         a1 > 0 | d < -5),
                           aes(label = category), size = 3) + 
  scale_color_discrete(guide = FALSE) + 
  xlab("Discrimination") + 
  ylab("Difficulty f2")

cowplot::plot_grid(a, b)
```

Not super easy to interpret what it does to difficulty and discrimination other than seeming to spread out the space. 

Plot the two difficulty parameters against one another. 

```{r}

a <- ggplot(coefs_2f, aes(x = a1, y = a2, col = category)) + 
  geom_point(alpha = .5)  +
  scale_color_discrete(guide=FALSE) + 
  ggtitle("Individual Milestones")

b <- coefs_2f %>%
  group_by(category) %>%
  summarise(a1 = mean(a1), 
            a2 = mean(a2)) %>%
  ggplot(aes(x = a1, y = a2, col = category)) + 
  geom_point(alpha = .5) + 
  ggrepel::geom_text_repel(aes(label = category), size = 3) +
  scale_color_discrete(guide=FALSE) + 
  ggtitle("Categories")

cowplot::plot_grid(a,b)
  
```

Table of coefficients. 

```{r}
coefs_2f$ratio <- coefs_2f$a1/coefs_2f$a2
coefs_2f$diff <- coefs_2f$a1 - coefs_2f$a2

c2f <- mutate_if(coefs_2f, is.numeric, function(x) round(x, digits = 2)) %>%
  select(-code, -short_name)

DT::datatable(c2f)
```

Now look at upper and lower bounds. 

```{r}
coefs_2f <- left_join(coefs_2f, milestones)

ggplot(coefs_2f,  
       aes(x = g, y = u, col = category)) + 
  geom_point(alpha = .6) + 
  ggrepel::geom_text_repel(data = filter(coefs_2f, 
                                         g > .5 | u < .5),
                           aes(label = category), size = 3) + 
  scale_color_discrete(guide = FALSE) +
  xlim(0,1) + 
  ylim(0,1) + 
  xlab("Lower Bound") + 
  ylab("Upper Bound")
```

But this is interesting - it really reduces those low upper bound items from the previous model, suggesting that it's explaining those in terms of person-level variability.
